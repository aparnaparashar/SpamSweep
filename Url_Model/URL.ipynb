{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b429e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aparn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:52:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com --> phishing\n",
      "http://bit.ly/fakepaypal-login --> phishing\n"
     ]
    }
   ],
   "source": [
    "# Cleaned and corrected URL Classification Project (single file)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from urllib.parse import urlparse\n",
    "from tld import get_tld\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ------------------ Feature Functions ------------------\n",
    "def having_ip_address(url):\n",
    "    match = re.search(r'(([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.){3}([01]?\\d\\d?|2[0-4]\\d|25[0-5])', url)\n",
    "    return 1 if match else 0\n",
    "\n",
    "def abnormal_url(url):\n",
    "    hostname = urlparse(url).hostname\n",
    "    return 1 if hostname and hostname in url else 0\n",
    "\n",
    "def count_dot(url): return url.count('.')\n",
    "def count_www(url): return url.count('www')\n",
    "def count_atrate(url): return url.count('@')\n",
    "def no_of_dir(url): return urlparse(url).path.count('/')\n",
    "def no_of_embed(url): return urlparse(url).path.count('//')\n",
    "\n",
    "def shortening_service(url):\n",
    "    match = re.search(r'bit\\.ly|tinyurl\\.com|goo\\.gl|t\\.co|ow\\.ly|buff\\.ly|adf\\.ly', url)\n",
    "    return 1 if match else 0\n",
    "\n",
    "def count_https(url): return url.count('https')\n",
    "def count_http(url): return url.count('http')\n",
    "\n",
    "def fd_length(url):\n",
    "    path = urlparse(url).path\n",
    "    try:\n",
    "        return len(path.split('/')[1])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def tld_length(tld):\n",
    "    try:\n",
    "        return len(tld)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "# ------------------ Load and Encode Data ------------------\n",
    "df = pd.read_csv(\"malicious_phish.csv\")  # Ensure this file exists\n",
    "X_raw = df['url']\n",
    "y = df['type']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# ------------------ Feature Extraction ------------------\n",
    "def extract_features(url):\n",
    "    return [\n",
    "        having_ip_address(url),\n",
    "        abnormal_url(url),\n",
    "        count_dot(url),\n",
    "        count_www(url),\n",
    "        count_atrate(url),\n",
    "        no_of_dir(url),\n",
    "        no_of_embed(url),\n",
    "        shortening_service(url),\n",
    "        count_https(url),\n",
    "        count_http(url),\n",
    "        fd_length(url),\n",
    "        tld_length(get_tld(url, fail_silently=True))\n",
    "    ]\n",
    "\n",
    "X_features = X_raw.apply(extract_features).tolist()\n",
    "X = np.array(X_features)\n",
    "\n",
    "# ------------------ Train Model ------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ------------------ Save Model ------------------\n",
    "with open(\"xgb_c.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "# ------------------ Prediction Function ------------------\n",
    "def predict_url_class(url):\n",
    "    with open(\"xgb_c.pkl\", \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "        le = pickle.load(f)\n",
    "\n",
    "    features = np.array(extract_features(url)).reshape(1, -1)\n",
    "    pred = model.predict(features)[0]\n",
    "    return le.inverse_transform([pred])[0]\n",
    "\n",
    "# ------------------ Test Predictions ------------------\n",
    "test_urls = [\n",
    "    \"https://www.google.com\",\n",
    "    \"http://bit.ly/fakepaypal-login\"\n",
    "]\n",
    "\n",
    "for url in test_urls:\n",
    "    print(f\"{url} --> {predict_url_class(url)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
